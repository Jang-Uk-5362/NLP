{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jang-Uk-5362/data-science/blob/main/NLP_generation_train\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U3MeuPe4HkP"
      },
      "source": [
        "!pip install ratsnlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCGKzLXJuED"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtoPBSH4v31j"
      },
      "source": [
        "# 모델 환경 설정(Hyperparameter settings)\n",
        "import torch\n",
        "from ratsnlp.nlpbook.generation import GenerationTrainArguments # TrainArguments 인자\n",
        "args = GenerationTrainArguments(\n",
        "    pretrained_model_name=\"skt/kogpt2-base-v2\", # 프리트레인을 마친 언어 모델의 이름\n",
        "    downstream_corpus_name=\"nsmc\", # 다운스트림 데이터 이름(구체적인 과제를 수행할 데이터))\n",
        "    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-generation\", # 파인튜닝한 모델의 체크포인트가 저장될 위치\n",
        "    max_seq_length=32,#토큰 기준 입력 문장 최대 길이\n",
        "    batch_size=32 if torch.cuda.is_available() else 4,\n",
        "    learning_rate=5e-5, #(보폭)\n",
        "    epochs=3,\n",
        "    tpu_cores=0 if torch.cuda.is_available() else 8,\n",
        "    seed=7, # 랜덤시드\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48RjaTAr7D4M"
      },
      "source": [
        "# 랜덤 시드 고정\n",
        "학습 재현을 위해 랜덤 시드를 고정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuacSUSd7JRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3eb5dc9-7eaa-4c71-8327-4b020a75084a"
      },
      "source": [
        "from ratsnlp import nlpbook\n",
        "nlpbook.set_seed(args)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set seed: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeTvf0bc9bbV"
      },
      "source": [
        "# 로거 설정\n",
        "메세지 출력 등을 위한 logger를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "251gdehZ9iPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236b8b50-f390-40c3-e00a-b15a1bbc9ef2"
      },
      "source": [
        "nlpbook.set_logger(args)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ratsnlp:Training/evaluation parameters GenerationTrainArguments(pretrained_model_name='skt/kogpt2-base-v2', downstream_task_name='sentence-generation', downstream_corpus_name='nsmc', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-generation', max_seq_length=32, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, cpu_workers=2, fp16=False, tpu_cores=0)\n",
            "INFO:ratsnlp:Training/evaluation parameters GenerationTrainArguments(pretrained_model_name='skt/kogpt2-base-v2', downstream_task_name='sentence-generation', downstream_corpus_name='nsmc', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-generation', max_seq_length=32, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, cpu_workers=2, fp16=False, tpu_cores=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqUazvWL7Pry"
      },
      "source": [
        "# 말뭉치 다운로드\n",
        "실습에 사용할 말뭉치(NSMC)를 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyaJgPA7Zxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e7f646-07a8-470a-bbaa-9047af4aaffb"
      },
      "source": [
        "# 네이버 영화 리뷰 말뭉치(한국어)\n",
        "from Korpora import Korpora\n",
        "Korpora.fetch(\n",
        "    corpus_name=args.downstream_corpus_name,\n",
        "    root_dir=args.downstream_corpus_root_dir,\n",
        "    force_download=args.force_download,\n",
        ")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Korpora] Corpus `nsmc` is already installed at /content/Korpora/nsmc/ratings_train.txt\n",
            "[Korpora] Corpus `nsmc` is already installed at /content/Korpora/nsmc/ratings_test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DnwLCKB7cRq"
      },
      "source": [
        "# 토크나이저 준비\n",
        "토큰화를 수행하는 토크나이저를 선언합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlcoBivi7hIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53fc3c3-1538-47df-ae33-6bfd2798b02a"
      },
      "source": [
        "# Preparing the tokenizer\n",
        "\n",
        "# Huggingface transformers 라이브러리\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    eos_token=\"</s>\", # GPT모델에서는 패딩할때 EOS토큰을 사용\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbLCM5e7i6g"
      },
      "source": [
        "# 학습데이터 구축\n",
        "학습데이터를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9s8znA17ovP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1821ecc7-faa4-4085-8087-13e43931b8fb"
      },
      "source": [
        "# Data preprocessing\n",
        "\n",
        "from ratsnlp.nlpbook.generation import NsmcCorpus, GenerationDataset\n",
        "corpus = NsmcCorpus()\n",
        "train_dataset = GenerationDataset(\n",
        "    args=args,\n",
        "    corpus=corpus,\n",
        "    tokenizer=tokenizer,\n",
        "    mode=\"train\",\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n",
            "INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n",
            "INFO:ratsnlp:loading train data... LOOKING AT /content/Korpora/nsmc/ratings_train.txt\n",
            "INFO:ratsnlp:loading train data... LOOKING AT /content/Korpora/nsmc/ratings_train.txt\n",
            "INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n",
            "INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n",
            "INFO:ratsnlp:tokenize sentences [took 10.820 s]\n",
            "INFO:ratsnlp:tokenize sentences [took 10.820 s]\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 부정 아 더빙.. 진짜 짜증나네요 목소리\n",
            "INFO:ratsnlp:sentence: 부정 아 더빙.. 진짜 짜증나네요 목소리\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁아 ▁더 빙 .. ▁진짜 ▁짜 증 나 네 요 ▁목소리 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁아 ▁더 빙 .. ▁진짜 ▁짜 증 나 네 요 ▁목소리 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 긍정 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
            "INFO:ratsnlp:sentence: 긍정 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
            "INFO:ratsnlp:tokens: ▁긍정 ▁흠 ... 포 스터 보고 ▁초 딩 영화 줄 .... 오 버 연기 조차 ▁가볍 지 ▁않 구나 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁긍정 ▁흠 ... 포 스터 보고 ▁초 딩 영화 줄 .... 오 버 연기 조차 ▁가볍 지 ▁않 구나 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 부정 너무재밓었다그래서보는것을추천한다\n",
            "INFO:ratsnlp:sentence: 부정 너무재밓었다그래서보는것을추천한다\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁너무 재 <unk> 었 다 그래 서 보는 것 을 추천 한다 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁너무 재 <unk> 었 다 그래 서 보는 것 을 추천 한다 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 부정 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
            "INFO:ratsnlp:sentence: 부정 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁교도 소 ▁이야기 구 먼 ▁ .. 솔 직 히 ▁재 미는 ▁없다. . 평 점 ▁조정 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁교도 소 ▁이야기 구 먼 ▁ .. 솔 직 히 ▁재 미는 ▁없다. . 평 점 ▁조정 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 긍정 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
            "INFO:ratsnlp:sentence: 긍정 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
            "INFO:ratsnlp:tokens: ▁긍정 ▁사이 몬 페 그의 ▁익살 스런 ▁연기가 ▁돋보 였던 ▁영화 ! 스파 이 더 맨 에서 ▁늙 어 보 이기 만 ▁했던 ▁커 스 틴 ▁던 스트가 ▁너무나 도 ▁이 뻐\n",
            "INFO:ratsnlp:tokens: ▁긍정 ▁사이 몬 페 그의 ▁익살 스런 ▁연기가 ▁돋보 였던 ▁영화 ! 스파 이 더 맨 에서 ▁늙 어 보 이기 만 ▁했던 ▁커 스 틴 ▁던 스트가 ▁너무나 도 ▁이 뻐\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722])\n",
            "INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n",
            "INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n",
            "INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_train_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 8.163 s]\n",
            "INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_train_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 8.163 s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]\n",
        "# 모델의 토큰별 확률 분포에서 lavels에 해당하는 확률은 높이고 이외의 토큰은 낮추는 방식으로 모델 전체를 업데이트하는 것이 파인튜닝의 과정이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah6LxItEflga",
        "outputId": "b37c7bf5-519e-4372-c598-9d0d8ef76af9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerationFeatures(input_ids=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a training data loader\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=RandomSampler(train_dataset, replacement=False), #샘플링 방식\n",
        "    # RandomSampler : 인스턴스를 랜덤 추출하는 역활을 하는 클래스\n",
        "    collate_fn=nlpbook.data_collator,# 뽑은 인스턴스들을 배치로 만드는 역활을 하는 함수\n",
        "    # nlpbook.data_collator: 같은 배치에서 인스턴스가 여렀을때 이를 input_ids,attention_mask 등 종류별로 모으고 파이토치가 요구하는 자료형인 텐서 형태로 바꾸는 역활을 수행합니다\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")"
      ],
      "metadata": {
        "id": "RLGoVtprfFW2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOAACuBY7vem"
      },
      "source": [
        "# 테스트 데이터 구축\n",
        "학습 중에 평가할 테스트 데이터를 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcm1tgfq7y84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4584a5a7-6212-4c04-f2ad-db3644e9fdcf"
      },
      "source": [
        "# Building a data loader for evaluation\n",
        "from torch.utils.data import SequentialSampler\n",
        "# SequentialSampler 인스턴스를 batch_size만큼 순서대로 추출하는 역활\n",
        "val_dataset = GenerationDataset(\n",
        "    args=args,\n",
        "    corpus=corpus,\n",
        "    tokenizer=tokenizer,\n",
        "    mode=\"test\",\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=SequentialSampler(val_dataset),\n",
        "    collate_fn=nlpbook.data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n",
            "INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n",
            "INFO:ratsnlp:loading test data... LOOKING AT /content/Korpora/nsmc/ratings_test.txt\n",
            "INFO:ratsnlp:loading test data... LOOKING AT /content/Korpora/nsmc/ratings_test.txt\n",
            "INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n",
            "INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n",
            "INFO:ratsnlp:tokenize sentences [took 4.274 s]\n",
            "INFO:ratsnlp:tokenize sentences [took 4.274 s]\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 긍정 굳 ㅋ\n",
            "INFO:ratsnlp:sentence: 긍정 굳 ㅋ\n",
            "INFO:ratsnlp:tokens: ▁긍정 ▁굳 ▁ ᄏ </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁긍정 ▁굳 ▁ ᄏ </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 부정 GDNTOPCLASSINTHECLUB\n",
            "INFO:ratsnlp:sentence: 부정 GDNTOPCLASSINTHECLUB\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁G D N T OP C LA S S I N T H EC L U B </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁G D N T OP C LA S S I N T H EC L U B </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 부정 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
            "INFO:ratsnlp:sentence: 부정 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁뭐 야 ▁이 ▁평 점 들은 .... ▁나쁘 진 ▁않지만 ▁10 점 ▁짜 리는 ▁더 더 욱 ▁아니 잖 아 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁뭐 야 ▁이 ▁평 점 들은 .... ▁나쁘 진 ▁않지만 ▁10 점 ▁짜 리는 ▁더 더 욱 ▁아니 잖 아 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 부정 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
            "INFO:ratsnlp:sentence: 부정 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁지루 하지는 ▁않은 데 ▁완전 ▁막 장 임 ... ▁돈 주고 ▁보 기에는 .... </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁지루 하지는 ▁않은 데 ▁완전 ▁막 장 임 ... ▁돈 주고 ▁보 기에는 .... </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:*** Example ***\n",
            "INFO:ratsnlp:sentence: 부정 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
            "INFO:ratsnlp:sentence: 부정 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁3D 만 ▁아니었 어도 ▁별 ▁다섯 ▁개 ▁ 줬 을 텐 데 .. ▁왜 ▁3D 로 ▁나와 서 ▁제 ▁심 기를 ▁불편 하게 ▁하 죠 ? ? </s> </s> </s> </s>\n",
            "INFO:ratsnlp:tokens: ▁부정 ▁3D 만 ▁아니었 어도 ▁별 ▁다섯 ▁개 ▁ 줬 을 텐 데 .. ▁왜 ▁3D 로 ▁나와 서 ▁제 ▁심 기를 ▁불편 하게 ▁하 죠 ? ? </s> </s> </s> </s>\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1])\n",
            "INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n",
            "INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n",
            "INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_test_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 4.491 s]\n",
            "INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_test_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 4.491 s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HztMCywb70e9"
      },
      "source": [
        "# 모델 초기화\n",
        "프리트레인이 완료된 GPT2 모델을 읽고, 문장 생성 모델을 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "staYwMx88MWQ"
      },
      "source": [
        "# GPT2LMHeadModel : KoGPT2가 프리트레인 할때 썻던 모델 클래스\n",
        "# 프리트레인 태스크와 파인튜닝 테스크가 동일 ('다음 단어 맞히기')\n",
        "from transformers import GPT2LMHeadModel\n",
        "model = GPT2LMHeadModel.from_pretrained(\n",
        "    args.pretrained_model_name\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYtJXijM8PN8"
      },
      "source": [
        "# 학습 준비\n",
        "Task와 Trainer를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FFn4MSz8SWu"
      },
      "source": [
        "# 파이토치 라이트닝(pytorch lightning) 모듈을 상속 받아 태스크(task)를 정의합니다\n",
        "from ratsnlp.nlpbook.generation import GenerationTask\n",
        "task = GenerationTask(model, args)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18W4vRtR8UTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d71447-724a-4a5e-a932-5672fdf0a1df"
      },
      "source": [
        "trainer = nlpbook.get_trainer(args)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True, used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KteHdhBT8X0e"
      },
      "source": [
        "# 학습\n",
        "준비한 데이터와 모델로 학습을 시작합니다. 학습 결과물(체크포인트)은 미리 연동해둔 구글 드라이브의 준비된 위치(`/gdrive/My Drive/nlpbook/checkpoint-generation`)에 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDr3M_nF8l7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "55444828-61f9-4a7e-e468-854b5f7cbd03"
      },
      "source": [
        "trainer.fit(\n",
        "    task,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=val_dataloader,\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-23b1c3039249>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WdsplPuEp0qU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}